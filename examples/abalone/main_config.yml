meta:
  data_name: "abalone"
  experiment_name: "trial_00"
  start_fresh: True

logging:
  console:
    format_str: null
    level: "info"
  file:
    format_str: null
    level: "info"
  track:
    tensorboard:
      param_steps: 50
    tracker_steps: 30

performance:
  objectives:
    # each objective can be a loss, a metric, or a combination of both
    main_obj:
      loss:
        # each loss can only be one loss
        type: "MSE"
        track: "mean" # only mean is supported currently
        #options:
      metric:
        # there can be many metrics
        # TODO: support custom metrics
        type: "MeanSquaredError"
        options: null
      in_config:
        type: "supervised"
        options:
          prediction: "reshape_out"
          target: "target_v"
        dataset: "abalone" # TODO: this could be infered if only one dataset is used?
    second_obj:
      loss:
        type: "MAE"
        track: "mean"
        #options:
      metric:
        type: "meanabsoluteerror"
        options: null
      in_config:
        type: "supervised"
        options:
          prediction: "reshape_out"
          target: "target_v"
        dataset: "abalone"

# TODO: this section needs to be redone
# TODO: this section should have different names for different datasets
data:
  datasets:
    "abalone":
      in:
        feature_a:
          shape: [2, 1]
          dtype: "float64"
        target_v:
          shape: [1, 1]
          dtype: "int32"
          label: True
      split:
        names: ["train", "val", "test"]

optimize:
  # NOTE: multiple losses by the same optimizer, are currently only modeled
  # jointly, if we wish to model the losses seperately (sequentially or
  # alternating), then we would want to use a second optimizer
  # optimizers:
  #   "main_opt":
  #     type: 'adam'
  #     options:
  #       learning_rate: 0.0001
  #       beta_1: 0.91
  #     objectives: ["main_obj", "second_obj"]
  optimizers:
    "main_opt":
      type: "adam"
      options:
        learning_rate: 0.0001
        beta_1: 0.91
      objectives: ["main_obj"]
    "second_opt":
      type: "adam"
      options:
        learning_rate: 0.0002
        beta_1: 0.92
      objectives: ["second_obj"]
  # directive:
  #   # (a|b): alternate, (a&b): joint, (a,b): sequential
  #   # eventually, we should be able to specify time/epoch/% before moving to the
  #   # next instruction, but presently each `opt` represents an (ENTIRE) pass of the training set
  #   # instruct: "(a|b)"
  #   instructions: "((main_opt, second_opt) & second_opt)"
  #   # TODO: handle case where not present
  #   #instructions: "(main_opt,second_opt)"

hyper_parameters:
  epochs: 20
  dataset:
    batch: 16
    shuffle_buffer: 128

callbacks:
  objects:
    "custom_printer":
      type: "printer"
      options:
        monitor: "my_monitor"
        relation_key: "global"

model: "parse_path::./model_config.yml"
